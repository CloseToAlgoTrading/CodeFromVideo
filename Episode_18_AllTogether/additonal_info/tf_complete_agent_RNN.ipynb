{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
      " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "from absl import logging\n",
    "\n",
    "sys.path.append('Enviroment')\n",
    "from tf_trade_enviroment import MyTradeEnv\n",
    "\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.environments import tf_py_environment\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.networks import q_rnn_network\n",
    "from tf_agents.utils import common\n",
    "\n",
    "from learningClass import learningHelper\n",
    "\n",
    "\n",
    "logging.set_verbosity(logging.INFO)\n",
    "tf.random.set_seed(12)\n",
    "tf.print(tf.config.list_physical_devices('GPU') )\n",
    "tf.print(tf.__version__)\n",
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read OCHLV data from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_train = ['AAPL', 'C', 'SPY', 'QQQ', 'WYNN', 'NVDA', 'VNET', 'GOLD', 'UBS']\n",
    "stocks_test = ['MSFT', 'AA', 'GPRO', 'AMD']\n",
    "history_range = {'start': datetime.datetime(1990, 1, 1), \n",
    "                 'end': datetime.datetime(2020, 10, 1)}\n",
    "history_range_test = {'start': datetime.datetime(2020, 10, 1), \n",
    "                 'end': datetime.datetime(2020, 11, 21)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and validate enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "action_spec: BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action', minimum=0, maximum=3)\ntime_step_spec.observation: {'price': BoundedArraySpec(shape=(20, 5), dtype=dtype('float32'), name='obs_price', minimum=0.0, maximum=3.4028234663852886e+38), 'pos': BoundedArraySpec(shape=(2,), dtype=dtype('int32'), name='obs_pos', minimum=0, maximum=1)}\ntime_step_spec.step_type: ArraySpec(shape=(), dtype=dtype('int32'), name='step_type')\ntime_step_spec.discount: BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)\ntime_step_spec.reward: ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
     ]
    }
   ],
   "source": [
    "environment = MyTradeEnv(stocks_train, history_range)\n",
    "utils.validate_py_environment(environment, episodes=2)\n",
    "\n",
    "print('action_spec:', environment.action_spec())\n",
    "print('time_step_spec.observation:', environment.time_step_spec().observation)\n",
    "print('time_step_spec.step_type:', environment.time_step_spec().step_type)\n",
    "print('time_step_spec.discount:', environment.time_step_spec().discount)\n",
    "print('time_step_spec.reward:', environment.time_step_spec().reward)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create traning and validation enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = tf_py_environment.TFPyEnvironment(MyTradeEnv(stocks_train, history_range))\n",
    "eval_env = tf_py_environment.TFPyEnvironment(MyTradeEnv(stocks_test, history_range_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define trainig paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create q_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network configuration\n",
    "input_fc_layer_params = (40,)\n",
    "lstm_size=(20,)\n",
    "output_fc_layer_params=(20,)\n",
    "\n",
    "# as we are using dictionary in our enviroment, we will create preprocessing layer\n",
    "preprocessing_layers = {\n",
    "    'price': tf.keras.layers.Flatten(),\n",
    "    'pos': tf.keras.layers.Dense(2)\n",
    "    }\n",
    "preprocessing_combiner = tf.keras.layers.Concatenate(axis=-1)\n",
    "\n",
    "#create a q_RNNnet\n",
    "q_net = q_rnn_network.QRnnNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    preprocessing_layers=preprocessing_layers,\n",
    "    preprocessing_combiner=preprocessing_combiner,\n",
    "    input_fc_layer_params=input_fc_layer_params,\n",
    "    lstm_size=lstm_size,\n",
    "    output_fc_layer_params=output_fc_layer_params)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the DQN-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create optimizer\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "#create a global step coubter\n",
    "#train_step_counter = tf.Variable(0)\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "#create agent\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    #train_step_counter=train_step_counter)\n",
    "    train_step_counter=global_step)\n",
    "\n",
    "agent.initialize()\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:absl:selected agent collect_policy\n",
      "INFO:absl:No checkpoint available at ./rnn_chkp/checkpoint\n",
      "INFO:absl:No checkpoint available at ./rnn_chkp/policy_checkpoint\n",
      "INFO:absl:Initializing is done\n"
     ]
    }
   ],
   "source": [
    "magent = learningHelper(train_env=train_env, test_env=eval_env, agent=agent, global_step=global_step, \n",
    "                        collect_episodes = 3,\n",
    "                        collect_steps_per_iteration = 10000,\n",
    "                        eval_interval=5,\n",
    "                        replay_buffer_capacity=20000,\n",
    "                        batch_size=500,\n",
    "                        #collect_policy = mp,\n",
    "                        log_interval = 10,\n",
    "                        chkpdir='./rnn_chkp/',\n",
    "                        train_sequence_length = 5,\n",
    ")\n",
    "magent.restore_check_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/denis/miniconda3/envs/tf-agent/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py:1004: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n",
      "WARNING:tensorflow:From /home/denis/miniconda3/envs/tf-agent/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py:1004: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n",
      "WARNING:tensorflow:From /home/denis/miniconda3/envs/tf-agent/lib/python3.7/site-packages/tf_agents/drivers/dynamic_step_driver.py:203: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
      "WARNING:tensorflow:From /home/denis/miniconda3/envs/tf-agent/lib/python3.7/site-packages/tf_agents/drivers/dynamic_step_driver.py:203: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
      "Epoch: 1, global_step 21, epoch train time: 299.3964638710022\n",
      "CPU times: user 6min 8s, sys: 21.7 s, total: 6min 30s\n",
      "Wall time: 5min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss = magent.train_agent(1)\n",
    "#magent.train_agent_with_avg_ret_condition(50, 10000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:absl: \n\t\t EnvironmentSteps = 10\n\t\t AverageReturn = -0.8629794120788574\n\t\t AverageEpisodeLength = 10.0\n\t\t NumberOfEpisodes = 1\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1):\n",
    "    magent.evaluate_agent(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/denis/miniconda3/envs/tf-agent/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/denis/miniconda3/envs/tf-agent/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./rnn_chkp/policy/assets\n",
      "INFO:tensorflow:Assets written to: ./rnn_chkp/policy/assets\n"
     ]
    }
   ],
   "source": [
    "magent.save_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "magent.store_check_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "magent.restore_check_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tf-agent': conda)",
   "metadata": {
    "interpreter": {
     "hash": "82aeabc757d6c78c27c0c57f6b7d31d2acb5bb3d554d0c4a8085045227445671"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}